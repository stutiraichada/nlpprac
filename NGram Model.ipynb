{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91636\\AppData\\Local\\Programs\\Python\\Python312\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install numpy pandas nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\91636\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams ,  trigrams\n",
    "from collections import Counter , defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2-grams:\n",
      "('The', 'quick')\n",
      "('quick', 'brown')\n",
      "('brown', 'fox')\n",
      "('fox', 'jumps')\n",
      "('jumps', 'over')\n",
      "('over', 'the')\n",
      "('the', 'lazy')\n",
      "('lazy', 'dog.')\n",
      "('dog.', 'The')\n",
      "('The', 'cats')\n",
      "('cats', 'sat')\n",
      "('sat', 'on')\n",
      "('on', 'the')\n",
      "('the', 'mats.')\n",
      "('mats.', 'She')\n",
      "('She', 'likes')\n",
      "('likes', 'to')\n",
      "('to', 'read')\n",
      "('read', 'books.')\n",
      "('books.', 'It')\n",
      "('It', 'is')\n",
      "('is', 'raining')\n",
      "('raining', 'outside')\n",
      "('outside', 'today.')\n"
     ]
    }
   ],
   "source": [
    "def ngrams(input_text, n):\n",
    "\n",
    "    tokens = input_text.split()  # Split the text into tokens (words)\n",
    "    n_grams = []\n",
    "\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        n_gram = tuple(tokens[i:i + n])\n",
    "        n_grams.append(n_gram)\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "# Example corpus\n",
    "corpus = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The cats sat on the mats.\",\n",
    "    \"She likes to read books.\",\n",
    "    \"It is raining outside today.\"\n",
    "]\n",
    "\n",
    "# Concatenate sentences into a single string\n",
    "corpus_text = ' '.join(corpus)\n",
    "\n",
    "# Ask for user input for the value of n\n",
    "try:\n",
    "    n_value = int(input(\"Enter the n-gram size  : \"))\n",
    "\n",
    "    if n_value < 1:\n",
    "        raise ValueError(\"The n-gram size must be a positive integer.\")\n",
    "\n",
    "    # Generate n-grams\n",
    "    result = ngrams(corpus_text, n_value)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Generated {n_value}-grams:\")\n",
    "    for grams in result:\n",
    "        print(grams)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid input: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "('चालाक', 'भूरी') 1\n",
      "('भूरी', 'लोमड़ी') 1\n",
      "('लोमड़ी', 'आलसी') 1\n",
      "('आलसी', 'कुत्ते') 1\n",
      "('कुत्ते', 'के') 1\n",
      "('के', 'ऊपर') 1\n",
      "('ऊपर', 'कूद') 1\n",
      "('कूद', 'जाती') 1\n",
      "('जाती', 'है।') 1\n",
      "('है।', 'बिल्ली') 1\n",
      "('बिल्ली', 'चटाई') 1\n",
      "('चटाई', 'पर') 1\n",
      "('पर', 'बैठी') 1\n",
      "('बैठी', 'हैं।') 1\n",
      "('हैं।', 'उसे') 1\n",
      "('उसे', 'किताबें') 1\n",
      "('किताबें', 'पढ़ना') 1\n",
      "('पढ़ना', 'पसंद') 1\n",
      "('पसंद', 'है।') 1\n",
      "('है।', 'आज') 1\n",
      "('आज', 'बाहर') 1\n",
      "('बाहर', 'बारिश') 1\n",
      "('बारिश', 'हो') 1\n",
      "('हो', 'रही') 1\n",
      "('रही', 'है।') 1\n",
      "\n",
      "Trigrams:\n",
      "('चालाक', 'भूरी', 'लोमड़ी') 1\n",
      "('भूरी', 'लोमड़ी', 'आलसी') 1\n",
      "('लोमड़ी', 'आलसी', 'कुत्ते') 1\n",
      "('आलसी', 'कुत्ते', 'के') 1\n",
      "('कुत्ते', 'के', 'ऊपर') 1\n",
      "('के', 'ऊपर', 'कूद') 1\n",
      "('ऊपर', 'कूद', 'जाती') 1\n",
      "('कूद', 'जाती', 'है।') 1\n",
      "('जाती', 'है।', 'बिल्ली') 1\n",
      "('है।', 'बिल्ली', 'चटाई') 1\n",
      "('बिल्ली', 'चटाई', 'पर') 1\n",
      "('चटाई', 'पर', 'बैठी') 1\n",
      "('पर', 'बैठी', 'हैं।') 1\n",
      "('बैठी', 'हैं।', 'उसे') 1\n",
      "('हैं।', 'उसे', 'किताबें') 1\n",
      "('उसे', 'किताबें', 'पढ़ना') 1\n",
      "('किताबें', 'पढ़ना', 'पसंद') 1\n",
      "('पढ़ना', 'पसंद', 'है।') 1\n",
      "('पसंद', 'है।', 'आज') 1\n",
      "('है।', 'आज', 'बाहर') 1\n",
      "('आज', 'बाहर', 'बारिश') 1\n",
      "('बाहर', 'बारिश', 'हो') 1\n",
      "('बारिश', 'हो', 'रही') 1\n",
      "('हो', 'रही', 'है।') 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Define the corpus\n",
    "corpus = [\n",
    "    \"चालाक भूरी लोमड़ी आलसी कुत्ते के ऊपर कूद जाती है।\",\n",
    "    \"बिल्ली चटाई पर बैठी हैं।\",\n",
    "    \"उसे किताबें पढ़ना पसंद है।\",\n",
    "    \"आज बाहर बारिश हो रही है।\"\n",
    "]\n",
    "\n",
    "# Tokenize each sentence in the corpus\n",
    "tokens = []\n",
    "for sentence in corpus:\n",
    "    tokens.extend(sentence.split())\n",
    "\n",
    "# Define function to generate n-grams\n",
    "def generate_ngrams(tokens, n):\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Generate bigrams and trigrams\n",
    "bigrams = generate_ngrams(tokens, 2)\n",
    "trigrams = generate_ngrams(tokens, 3)\n",
    "\n",
    "# Count frequency of each n-gram\n",
    "bigram_counts = Counter(bigrams)\n",
    "trigram_counts = Counter(trigrams)\n",
    "\n",
    "# Display results\n",
    "print(\"Bigrams:\")\n",
    "for bigram, count in bigram_counts.items():\n",
    "    print(bigram, count)\n",
    "\n",
    "print(\"\\nTrigrams:\")\n",
    "for trigram, count in trigram_counts.items():\n",
    "    print(trigram, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
